{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summarystatistics.py \n",
    "\n",
    "### Jay Sayre - sayrejay (at) gmai|\n",
    "\n",
    "Computes basic summary statistics in python for use in my paper\n",
    "\n",
    "## Inputs:\n",
    "\n",
    "'IPUMS/ipumsclean.csv' - cleaned IPUMS data  (by 01182016ipumscleaning.ipynb) for DR in 2002 and 2010\n",
    "\n",
    "\"../DHS/2013Standard/geo/merge2013clust.csv\" - DHS 2013 Dominican Republic geospatial data corresponding to geo-tagged keys in DHS 2013 dataset, compiled by extractoneshapefiletopoint.py\n",
    "\n",
    "\"../DHS/2013Standard/hhmember/DRPR61FL.csv\" - DHS 2013 Dominican Republic Household Member Dataset (converted to csv by DHS/DHSbuild.R script)\n",
    "\n",
    "\"/cafta-dr/DHS/DHSoccupationsISIC.xlsx\" - Code for converting DHS occupation categories into ISIC occupation codes\n",
    "\n",
    "usd2013todrXXpesos - Nominal conversion rate from 2013 USD to 20XX RD.\n",
    "\n",
    "'mun_level_isic4dig_DATASET.csv' - contains income and tariff levels at\n",
    "for 2002 and 2013 at the municipality level (using ISIC four digit, just empresas), to be analyzed later in R\n",
    "or STATA\n",
    "\n",
    "'municipality_level_DATASET.csv' - contains income and tariff levels at\n",
    "for 2002 and 2013 at the municipality level (using ISIC two digit, IPUMS+empresas), to be analyzed later in R\n",
    "or STATA\n",
    "\n",
    "'municipality_occupation_level_DATASET.csv' - contains income and tariff levels for 2002 and 2013 at the municipality and occupational level, to be analyzed later in R or STATA\n",
    "\n",
    "'municipality_migration_DATASET.csv' - contains contains population estimates for 2002 and 2010 and tariff levels for 2002 and 2010 at the municipality level\n",
    "\n",
    "'muncorrespondence.xlsx' - Used to match up province names to codes\n",
    "\n",
    "## Outputs:\n",
    "\n",
    "'cafta-dr/Plots/summarytable.tex' - Summary statistics at municipality level\n",
    "\n",
    "'cafta-dr/Plots/provsummarytable.tex' - Summary statistics for each province, split up into several tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.name == 'nt':\n",
    "    basedir =\"D:/Dropbox/Dropbox (Personal)/College/DR_Paper/\"\n",
    "else:\n",
    "    basedir =\"/home/j/Dropbox/College/DR_Paper/\"\n",
    "\n",
    "## INPUTS\n",
    "munisic4output = basedir+'cafta-dr/Output/mun_level_isic4dig_DATASET.csv'\n",
    "munoutput = basedir+'cafta-dr/Output/municipality_level_DATASET.csv'\n",
    "munoccoutput = basedir+'cafta-dr/Output/municipality_occupation_level_DATASET.csv'\n",
    "ipumsinputdata = basedir+'IPUMS/ipumsclean.csv'\n",
    "dhs_geoclust_2013 = basedir + \"DHS/2013Standard/geo/merge2013clust.csv\"\n",
    "dhs_hhmember_2013 = basedir + \"DHS/2013Standard/hhmember/DRPR61FL.csv\" # Converted to csv by DHSbuild.R in  main directory\n",
    "dhs_occupations_conversion = basedir+\"cafta-dr/DHS/DHSoccupationsISIC.xlsx\"\n",
    "munmigroutput = basedir+'cafta-dr/Output/municipality_migration_DATASET.csv' \n",
    "province_names = basedir+'cafta-dr/DR_Codigos/Output/muncorrespondence.csv'\n",
    "\n",
    "## Conversion rate from RD to 2013 USD \n",
    "usd2013todr13pesos = 41.8081439153#*(0.985) ## Later term is so currency is wrt to 2010 constant USD, from World Bank\n",
    "usd2013todr02pesos = 18.609825#*(0.975)\n",
    "\n",
    "## OUTPUT \n",
    "summarytable = basedir+'cafta-dr/Plots/summarytable.tex'\n",
    "provsumtable1 = basedir+'cafta-dr/Plots/provsummarytable1.tex'\n",
    "provsumtable2 = basedir+'cafta-dr/Plots/provsummarytable2.tex'\n",
    "\n",
    "## Helper function to rename columns \n",
    "def rename_columns(col):\n",
    "    if col == 'inc02': return 'income2002'\n",
    "    elif col == 'edu02': return 'edu2002'\n",
    "    elif col == 'grossalary13': return 'income2013'\n",
    "    elif col == 'occinc13': return 'income2013'\n",
    "    elif col == 'frstsourcinc13': return 'income2013'\n",
    "    elif col == 'edu10': return 'edu2010'\n",
    "    elif col == 'edu13': return 'edu2013'\n",
    "    elif col == 'duty02': return 'duty2002'\n",
    "    elif col == 'duty10': return 'duty2010'\n",
    "    elif col == 'duty13': return 'duty2013'\n",
    "    elif col == 'pop02': return 'pop2002'\n",
    "    elif col == 'pop10': return 'pop2010'\n",
    "    elif col == 'PROV': return 'prov'\n",
    "    elif col == 'PROVNAME': return 'Province'\n",
    "    elif col == 'empop02': return 'empop2002'\n",
    "    elif col == 'empop10': return 'empop2010'\n",
    "    elif col == 'workagepop02': return 'workagepop2002'\n",
    "    elif col == 'workagepop10': return 'workagepop2010'\n",
    "    elif col == 'numworkers02': return 'employment2002'\n",
    "    elif col == 'numworkers10': return 'employment2010'\n",
    "    elif col == 'firmconc02': return 'occconcentration2002'\n",
    "    elif col == 'firmconc10': return 'occconcentration2010'\n",
    "    else: return col\n",
    "\n",
    "## Removing accents in province names\n",
    "import unicodedata\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/j/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/j/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (503,509,511,547,550,553,555,558,559,634,635,637,708,709,711,787,788,790,811,837,838,839) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "### Summary statistics really need to be calculated at survey level\n",
    "### Code copied from DHSaggregation.py and IPUMSaggregation.py\n",
    "\n",
    "\n",
    "### IPUMS\n",
    "ipumsdf = pd.read_csv(ipumsinputdata, encoding='utf-8')\n",
    "ipumsdf = ipumsdf[ipumsdf[\"geo2_dox\"] != 'El Carril']\n",
    "## Clean up years of education in both data sets (2002 and 2010)\n",
    "def years_edu(edu):\n",
    "    if edu == 0: return None\n",
    "    elif edu == 100: return 0.0\n",
    "    elif edu == 201: return 0.25\n",
    "    elif edu == 202: return 0.50\n",
    "    elif edu == 203: return 0.75\n",
    "    elif edu == 301: return 1.0\n",
    "    elif edu == 302: return 2.0\n",
    "    elif edu == 303: return 3.0\n",
    "    elif edu == 304: return 4.0\n",
    "    elif edu == 305: return 5.0\n",
    "    elif edu == 306: return 6.0\n",
    "    elif edu == 307: return 7.0\n",
    "    elif edu == 308: return 8.0\n",
    "    elif edu == 411: return 9.0\n",
    "    elif edu == 412: return 10.0\n",
    "    elif edu == 413: return 11.0\n",
    "    elif edu == 414: return 12.0\n",
    "    elif edu == 501: return 13.0\n",
    "    elif edu == 502: return 14.0\n",
    "    elif edu == 503: return 15.0\n",
    "    elif edu == 504: return 16.0\n",
    "    elif edu == 505: return 16.25\n",
    "    elif edu == 506: return 16.5\n",
    "    elif edu == 511: return 17.0\n",
    "    elif edu == 512: return 17.25\n",
    "    elif edu == 521: return 17.0\n",
    "    elif edu == 522: return 18.0    \n",
    "    elif edu == 523: return 19.0\n",
    "    elif edu == 531: return 19.0\n",
    "    elif edu == 532: return 20.0\n",
    "    elif edu == 533: return 21.0\n",
    "    elif edu == 534: return 22.0\n",
    "    elif edu == 998: return None\n",
    "    else: return None\n",
    "ipumsdf['educdo'] = ipumsdf['educdo'].apply(lambda x: years_edu(x))\n",
    "\n",
    "## Drops columns I don't currently need to increase the speed of the script\n",
    "ipumsdropcols = ['country','sample','serial','persons','hhwt','subsamp','strata',\n",
    "                 'urban','regionw','geolev1','geo1_do','geo1_dox','subrdo','age',\n",
    "                 'sex','nativity','bplcountry','bpldo','yrimm','yrsimm','school','lit',\n",
    "                 'edattain','edattaind','empstat','empstatd','occisco','indgen','ind', \n",
    "                 'classwkd','empsect','migrate5','migctry5','migdo','disabled','disemp']\n",
    "ipumsdf.drop(ipumsdropcols,1, inplace=True)\n",
    "\n",
    "## Subset to only workers employed in the private sector\n",
    "ipumsdf = ipumsdf[ipumsdf['classwk'] == 2]\n",
    "\n",
    "## Split data set into 2002 and 2010 sections, we primarily care about 2002\n",
    "df2002, df2010 = ipumsdf[ipumsdf['year']==2002], ipumsdf[ipumsdf['year']==2010]\n",
    "\n",
    "## Relabel variables if I am also including 2010 variables\n",
    "df2010['edu10'] = df2010['educdo']\n",
    "df2010.drop('educdo',1,inplace=True)\n",
    "\n",
    "## Subsetting down to only obs with available (and nonzero) income data for 2002\n",
    "incdf = df2002[df2002['inctot']!= 9999998]\n",
    "incdf = incdf[incdf['inctot']!= 9999999]\n",
    "incdf = incdf[incdf['inctot']!= 0]\n",
    "## Convert income as measured in monthly 2002 RD to weekly 2013 USD\n",
    "incdf['inctot'] = incdf['inctot']/(usd2013todr02pesos*4.33)\n",
    "\n",
    "## Convert weekly income into estimated hourly wage based upon average working hours for each occupation category\n",
    "## For information on where these numbers come from, please see:\n",
    "## cafta-dr/DR_Codigos/Input/DRCentralBankAverageHoursWorkedbyOccupation.xls\n",
    "def avgworkhrs02(occ):\n",
    "    if occ in range(1,3+1):     return 38.38\n",
    "    elif occ in range(5,9+1):   return 44.51\n",
    "    elif occ in range(10,33+1): return 44.20\n",
    "    elif occ in range(35,39+1): return 44.14\n",
    "    elif occ in range(41,43+1): return 43.13\n",
    "    elif occ in range(45,47+1): return 44.54 #Not sure about my translation here\n",
    "    elif occ in range(55,56+1): return 41.51\n",
    "    elif occ in range(49,53+1): return 47.61\n",
    "    elif occ in range(58,63+1): return 47.61\n",
    "    elif occ in range(64,66+1): return 40.52\n",
    "    elif occ in range(77,84+1): return 41.53\n",
    "    elif occ == 84:             return 41.53\n",
    "    elif occ in range(94,96+1): return 38.11\n",
    "    else:                       return 41.85\n",
    "    \n",
    "incdf['hrsworked']=incdf['occ'].apply(lambda x: avgworkhrs02(x))\n",
    "incdf['inctot'] = incdf['inctot']/incdf['hrsworked']\n",
    "\n",
    "### DHS\n",
    "geo_df_2013 = pd.read_csv(dhs_geoclust_2013, encoding='latin_1')\n",
    "dhs_data_2013 = pd.read_csv(dhs_hhmember_2013, encoding='latin_1')\n",
    "\n",
    "## Subset geocluster datasets down to relevant variables\n",
    "geo_keep_cols = ['ADM1DHS','ALT_DEM',\"DHSCLUST\",\"MUN\",\"PROV\",\"REG\",\"URBAN_RURA\"]\n",
    "geo_df_2013 = geo_df_2013[geo_keep_cols]\n",
    "\n",
    "## Merge geodata with DHS data\n",
    "dhs_data_2013 = dhs_data_2013.merge(geo_df_2013, left_on=\"hv001\", right_on=\"DHSCLUST\", how=\"left\")\n",
    "\n",
    "### Clean 2013 DHS data\n",
    "\n",
    "## Convert occupations provided in espanol to ISIC two digit code\n",
    "## Build conversion dictionary\n",
    "occonversion = pd.read_excel(dhs_occupations_conversion,encoding='latin_1')\n",
    "occonversion['isic2digitV3']=occonversion['isic2digitV3'].astype(str)\n",
    "occonversion['isic2digitV3']=occonversion['isic2digitV3'].apply(lambda x: x.split(','))\n",
    "occonversion = dict(zip(occonversion['espanol'],occonversion['isic2digitV3']))\n",
    "occonversion['missing'] = '99'\n",
    "## Take steps necessary to convert occupations in 2013\n",
    "dhs_data_2013['sg110'] = dhs_data_2013['sg110'].fillna('missing')\n",
    "dhs_data_2013['sg110'] = dhs_data_2013['sg110'].apply(lambda x: occonversion[x.rstrip()])\n",
    "\n",
    "### Convert income to unified period, convert to 2013 USD\n",
    "## Convert income to correct periodicity, defaults to assuming pay is monthly since it is most common\n",
    "grosssalary_period_conv = {\"monthly\":12,'by weekly':26,'weekly':52,'yearly':1,\"don't know\":12}\n",
    "frstsourcinc_period_conv = {\"monthly\":12,'by weekly':26,'weekly':52,'yearly':1,\"don't know\":12}\n",
    "\n",
    "dhs_data_2013['sg112a'] = dhs_data_2013['sg112a'].apply(lambda x: x if x != 999998 else 0)\n",
    "dhs_data_2013['sg112b'] = dhs_data_2013['sg112b'].apply(lambda x: grosssalary_period_conv.get(x,12))\n",
    "dhs_data_2013['sg117b'] = dhs_data_2013['sg117b'].apply(lambda x: frstsourcinc_period_conv.get(x,12))\n",
    "\n",
    "## Convert income measured in DR 2013 (at different periods) to weekly 2013 USD\n",
    "dhs_data_2013['grossalary'] = (dhs_data_2013['sg112a']*dhs_data_2013['sg112b'])/(usd2013todr13pesos*52.0)\n",
    "dhs_data_2013['frstsourcinc'] = (dhs_data_2013['sg117a']*dhs_data_2013['sg117b'])/(usd2013todr13pesos*52.0)\n",
    "dhs_data_2013['occinc'] = (dhs_data_2013['singresoo']*12)/(usd2013todr13pesos*52.0)\n",
    "\n",
    "## Convert weekly income into estimated hourly wage based upon average working hours for each occupation category\n",
    "## For information on where these numbers come from, please see:\n",
    "## cafta-dr/DR_Codigos/Input/DRCentralBankAverageHoursWorkedbyOccupation.xls\n",
    "def avgworkhrs13(occ):\n",
    "    ## Checks to see if occ is a list\n",
    "    ## Has to be a better way to do this\n",
    "    try:\n",
    "        occ.sort()\n",
    "        occ = int(occ[0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if occ in range(1,3+1):     return 39.62\n",
    "    elif occ in range(5,9+1):   return 44.95\n",
    "    elif occ in range(10,33+1): return 44.23\n",
    "    elif occ in range(35,39+1): return 43.33\n",
    "    elif occ in range(41,43+1): return 41.97\n",
    "    elif occ in range(45,47+1): return 42.57 #Not sure about my translation here\n",
    "    elif occ in range(55,56+1): return 42.03\n",
    "    elif occ in range(49,53+1): return 45.38\n",
    "    elif occ in range(58,63+1): return 45.38\n",
    "    elif occ in range(64,66+1): return 41.30\n",
    "    elif occ in range(77,84+1): return 40.70\n",
    "    elif occ == 84:             return 40.70\n",
    "    elif occ in range(94,96+1): return 38.49\n",
    "    else:                       return 41.28\n",
    "\n",
    "dhs_data_2013['hrsworked'] = dhs_data_2013['sg110'].apply(lambda x: avgworkhrs13(x))\n",
    "dhs_data_2013['grossalary'] = dhs_data_2013['grossalary']/dhs_data_2013['hrsworked']\n",
    "dhs_data_2013['frstsourcinc'] = dhs_data_2013['frstsourcinc']/dhs_data_2013['hrsworked']\n",
    "dhs_data_2013['occinc'] = dhs_data_2013['occinc']/dhs_data_2013['hrsworked']\n",
    "\n",
    "## Clean up education data\n",
    "dhs_data_2013['yearsedu']=dhs_data_2013['hv108'].apply(lambda x: x if x != 98 else None)\n",
    "\n",
    "## Remove entries with null income data   \n",
    "dhs_data_2013 = dhs_data_2013[dhs_data_2013['grossalary'].astype(str) != 'nan']\n",
    "\n",
    "## Remove entries with unknown occupations\n",
    "dhs_data_2013 =  dhs_data_2013[dhs_data_2013['sg110'] != '99']\n",
    "\n",
    "### Compute survey level averages\n",
    "grossalary13 = dhs_data_2013['grossalary'].mean()\n",
    "frstinc13 = dhs_data_2013['frstsourcinc'].mean()\n",
    "occinc13 = dhs_data_2013['occinc'].mean()\n",
    "edu13 = dhs_data_2013['yearsedu'].mean()\n",
    "\n",
    "inc02 = incdf['inctot'].mean()\n",
    "edu02 = incdf['educdo'].mean()\n",
    "edu10 = df2010['edu10'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>duty</th>\n",
       "      <th>pop</th>\n",
       "      <th>empop</th>\n",
       "      <th>workagepop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>8.897335</td>\n",
       "      <td>55242.200000</td>\n",
       "      <td>20481.251613</td>\n",
       "      <td>33367.535484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2.675379</td>\n",
       "      <td>60937.296774</td>\n",
       "      <td>19544.870968</td>\n",
       "      <td>38656.716129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      duty           pop         empop    workagepop\n",
       "0  2002  8.897335  55242.200000  20481.251613  33367.535484\n",
       "1  2010  2.675379  60937.296774  19544.870968  38656.716129"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in migration table\n",
    "\n",
    "munmigdf = pd.read_csv(munmigroutput)\n",
    "munmigdf.drop(['mun','prov'],1,inplace=True)\n",
    "munmigdf.columns = [rename_columns(a) for a in munmigdf.columns]\n",
    "migcols = munmigdf.columns\n",
    "munmigdf['group'] = 1 \n",
    "munmigdf = munmigdf.groupby('group',as_index=False)[migcols].mean()\n",
    "munmigdf = pd.wide_to_long(munmigdf,['duty','pop','empop','workagepop'],i='group',j='year').reset_index()\n",
    "munmigdf.drop('group',1,inplace=True)\n",
    "munmigdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create a provincial level summary table\n",
    "\n",
    "provdf = pd.read_csv(munoutput)\n",
    "provdf.drop(['mun','occinc13','frstsourcinc13','edu10'],1,inplace=True)\n",
    "provdf.columns = [rename_columns(a) for a in provdf.columns]\n",
    "provdf = provdf.groupby('prov',as_index=False).mean()\n",
    "popdf = pd.read_csv(munmigroutput,encoding='utf-8')\n",
    "popdf.drop(['mun','duty02','duty10'],1,inplace=True)\n",
    "popdf.columns = [rename_columns(a) for a in popdf.columns]\n",
    "popdf = popdf.groupby('prov',as_index=False).sum()\n",
    "popdf['emprate2002'] = popdf['empop2002']/popdf['workagepop2002']\n",
    "popdf['emprate2010'] = popdf['empop2010']/popdf['workagepop2010']\n",
    "popdf.drop(['workagepop2002','workagepop2010'],1,inplace=True)\n",
    "provdf = provdf.merge(popdf,on='prov',how='left')\n",
    "## Merge in names of provinces\n",
    "munnamedf = pd.read_csv(province_names,encoding='utf-8')\n",
    "munnamedf.columns = [rename_columns(a) for a in munnamedf.columns]\n",
    "munnamedf = munnamedf[['prov','Province']]\n",
    "munnamedf = munnamedf.groupby('prov',as_index=False).first()\n",
    "provdf = provdf.merge(munnamedf,on='prov',how='left')\n",
    "provdf = provdf[['prov','Province']+sorted(list(provdf.columns)[1:-1])]\n",
    "provdf['Province'] = provdf['Province'].apply(lambda x: remove_accents(x).title())\n",
    "\n",
    "provdf1 = provdf[['Province','duty2002','duty2013','edu2002','edu2013','pop2002']]\n",
    "provdf2 = provdf[['Province','emprate2002','emprate2010','income2002',\n",
    "                  'income2013','pop2010']]\n",
    "\n",
    "provdf1.to_latex(provsumtable1, escape=False, index=False)\n",
    "provdf2.to_latex(provsumtable2, escape=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Summary table at the municipality level, used temporarily\n",
    "\n",
    "mundf = pd.read_csv(munoutput)\n",
    "mundf.drop(['prov','occinc13','grossalary13'],1,inplace=True)\n",
    "mundf['group'] = 1 \n",
    "\n",
    "mundf.columns = [rename_columns(a) for a in mundf.columns]\n",
    "mundf = mundf.groupby('group',as_index=False)[mundf.columns].mean()\n",
    "mundf = pd.wide_to_long(mundf,['duty','income','edu'],i='group',j='year').reset_index()\n",
    "mundf.drop(['group','mun'],1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>duty</th>\n",
       "      <th>income</th>\n",
       "      <th>employment</th>\n",
       "      <th>edu</th>\n",
       "      <th>pop</th>\n",
       "      <th>empop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>9.090764</td>\n",
       "      <td>1.431982</td>\n",
       "      <td>147.237795</td>\n",
       "      <td>9.140800</td>\n",
       "      <td>55242.200000</td>\n",
       "      <td>20481.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.751566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.752946</td>\n",
       "      <td>8.977756</td>\n",
       "      <td>60937.296774</td>\n",
       "      <td>19544.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.542419</td>\n",
       "      <td>1.469766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.177072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      duty    income  employment       edu           pop         empop\n",
       "0  2002  9.090764  1.431982  147.237795  9.140800  55242.200000  20481.251613\n",
       "1  2010  1.751566       NaN  190.752946  8.977756  60937.296774  19544.870968\n",
       "2  2013  1.542419  1.469766         NaN  8.177072           NaN           NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Summary table at the municipality level\n",
    "\n",
    "munoccdf = pd.read_csv(munoccoutput)\n",
    "munoccdf.drop(['munocc','occ','occinc13','grossalary13','nontraded','firmconc02','firmconc10'],1,inplace=True)\n",
    "munoccdf['group'] = 1 \n",
    "\n",
    "munoccdf.columns = [rename_columns(a) for a in munoccdf.columns]\n",
    "munoccdf = munoccdf.groupby('group',as_index=False)[munoccdf.columns].mean()\n",
    "munoccdf = pd.wide_to_long(munoccdf,['duty','income','employment','edu'],i='group',j='year').reset_index()\n",
    "munoccdf.drop('group',1,inplace=True)\n",
    "\n",
    "## Adds variables calculated at the survey level. May want to take a more sophisicated approach here.\n",
    "munoccdf.loc[0,'edu'] = edu02\n",
    "munoccdf.loc[1,'edu'] = edu10\n",
    "munoccdf.loc[2,'edu'] = edu13\n",
    "munoccdf.loc[0,'income'] = inc02\n",
    "munoccdf.loc[2,'income'] = frstinc13\n",
    "munoccdf.loc[0,'duty'] = mundf.loc[0,'duty']\n",
    "munoccdf.loc[2,'duty'] = mundf.loc[1,'duty']\n",
    "munoccdf['pop']=munmigdf['pop']\n",
    "munoccdf['empop']=munmigdf['empop']\n",
    "\n",
    "munoccdf.to_latex(summarytable, escape=False, index=False)\n",
    "munoccdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
