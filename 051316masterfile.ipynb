{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jay Sayre - sayrejay (at) gmai|\n",
    "\n",
    "\n",
    "This is the master script for my CAFTA-DR paper. If I end up caring enough, you should be able to simply run this script, which will run the others. If not, this will simply provide a reference for the workflow of my project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build correspondence table for IPUMS/DHS municipalities\n",
    "There is really no need to replicate this, but is done by\n",
    "DR_Cogidos/buildcorrespondence.py\n",
    "\n",
    "### WTO/CAFTA-DR tariff cleaning\n",
    "\n",
    "Inputs - Treaties/Treaty_Text (OCR files therein, to duplicate you need to open DRTARIFFSCHEDULE.ods and save it as .xls file)\n",
    "\n",
    "CAFTAtariffschedulecleaning.py - Cleans up OCR'ed duty table\n",
    "\n",
    "wtoandcaftatariffcleaning.py - Takes WTO HS6 tariff data (provided in separate excel files) and combines it into one dataset. Also takes CAFTA-DR treaty data and computes the expected tariff rate from 2007-on based upon treaty laws.\n",
    "\n",
    "\n",
    "### IPUMS cleaning\n",
    "Inputs - IPUMS dataset containing all variables for Dominican Republic\n",
    "in both 2002 and 2010\n",
    "../IPUMS/ipumscleaning.py or using modified IPUMS provided do file (modifications are changing the names of some municipalities)\n",
    "IPUMSdataaggregation.py\n",
    "\n",
    "### DHS cleaning\n",
    "Inputs - DHS datset for 2013 Dominican Republic containing the household member dataset + the geocoding clusters\n",
    "\n",
    "DHSmakevariablekey.R - In no way necessary for this process, but makes a csv file for each DHS dataset and dta file, in case you don't have access to Stata\n",
    "\n",
    "Run a script to convert dta file to csv's. I believe I used Stata, \n",
    "but one can also use \"DHS/DHSexplore.R\"\n",
    "\n",
    "DHS/extractoneshapefiletopoint.py - Using the python ArcGIS extension, extract ONE municipality polygons/information to DHS geo-clusters, picking which municipality is closest to each cluster\n",
    "\n",
    "DHS/dbftodata.py - Script to convert merged geoclust and D.R. municipality shapefiles to usable csvs\n",
    "\n",
    "DHSdataaggregation.py\n",
    "\n",
    "### Compute estimate of industrial activity within region\n",
    "Inputs - IPUMS estimates of workers in each occupation + Directory of Companies + Establishments provided by Dominican Republic ONE\n",
    "\n",
    "compute_regional_employment.py - Computes estimated share of employment in each municipality of the Dominican Republic for a given ISIC code\n",
    "\n",
    "\n",
    "### Compute estimates of average tariffs for a municipality\n",
    "Inputs - other than those produced by other scripts, uses a HS -> ISIC correspondence table provided by World Bank\n",
    "\n",
    "mergingtariffandindustrydata.py - converts tariff data from HS to ISIC and computes the average tariff for a municipality (if applicable)\n",
    "\n",
    "### Final data cleaning \n",
    "\n",
    "dataassembly.py - Combines various datasets for analysis, produced by earlier scripts\n",
    "\n",
    "### Data Analysis \n",
    "\n",
    "daTAanalysis.R - Main data analysis script, produces main tex tables\n",
    "\n",
    "datavisualization.R - Produces main plots and line graphs\n",
    "\n",
    "summarystatistics.py - Proudces main summary tables\n",
    "\n",
    "cleanuptextable.py - Cleans up tex tables and tikz plots produced by exploratoryanalysis.R and datavisualization.R scripts for paper\n",
    "\n",
    "makedominicanrepublicmap.R - Makes GIS plots of variables and saves them to pdf (tikz files are way too big)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Quick script written to automate process\n",
    "## Note that this does not call all necessary programs to run, see\n",
    "## documentation above for more information\n",
    "\n",
    "import subprocess, os\n",
    "\n",
    "if os.name == 'nt':\n",
    "    tdir = \"D:/Dropbox/Dropbox (Personal)/College/DR_Paper/cafta-dr\"    \n",
    "else:\n",
    "    tdir =\"/home/j/Dropbox/College/DR_Paper/cafta-dr\"\n",
    "\n",
    "scripts = []\n",
    "for path, dirs, files in os.walk(tdir):\n",
    "    pth = path.replace(tdir,'')\n",
    "    if '.git' not in pth and 'checkpoints' not in pth:\n",
    "        for fl in files:\n",
    "            if \".py\" in fl or \".R\" in fl:\n",
    "                if \".Rhistory\" not in fl and \".R~\" not in fl:\n",
    "                    if \".ipynb\" not in fl and \".py~\" not in fl:\n",
    "                        scripts.append(pth+'/'+fl)\n",
    "\n",
    "                       \n",
    "keywords = [\"tariffschedulecleaning\",\"wtoandcafta\",\"ipumscleaning\",\n",
    "           \"IPUMSdataaggregation\",\"DHSdataaggregation\",\n",
    "           \"compute_regional_employment\",\"mergingtariffandindustrydata\",\n",
    "           \"dataassembly\",\"daTAanalysis\",\"datavisualization\",\n",
    "            \"summarystatistics\", \"cleanuptextable\",\"makedominicanrepublicmap\"]\n",
    "            \n",
    "scripths = [[tdir+fl for fl in scripts if key in fl][0] for key in keywords]\n",
    "\n",
    "for scripth in scripths:\n",
    "    if '.R' in scripth:\n",
    "        subprocess.call(['R', scripth])\n",
    "    elif '.py' in scripth:\n",
    "        subprocess.call(['python', scripth])\n",
    "    else:\n",
    "        raise Exception"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
