{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DHSdataaggregation.py - Takes DHS data and\n",
    "aggregates the variables in the files (most importantly income and wage data) to the occupation and municipality level, after making necessary cleaning and merging steps\n",
    "\n",
    "Jay Sayre - sayrejay (at) gmail,\n",
    "\n",
    "INPUTS: \n",
    "\n",
    "\"../DHS/2013Standard/geo/merge2013clust.csv\" - DHS 2013 Dominican Republic geospatial data corresponding to geo-tagged keys in DHS 2013 dataset, compiled by extractoneshapefiletopoint.py\n",
    "\n",
    "\"../DHS/2013Standard/hhmember/DRPR61FL.csv\" - DHS 2013 Dominican Republic Household Member Dataset (converted to csv by DHS/DHSbuild.R script)\n",
    "\n",
    "Ditto for DHS 2007 data (don't think I'm using this)\n",
    "\n",
    "\"/cafta-dr/DHS/DHSoccupationsISIC.xlsx\" - Code for converting DHS occupation categories into ISIC occupation codes, compiled by author (me!)\n",
    "\n",
    "INTERMEDIATE DATA: N/A\n",
    "\n",
    "OUTPUTS: \"averageincomebymunicipality2013.csv\" - Average income in each D.R. municipality for 2013\n",
    "\n",
    "\"averageincomebyoccmun2013.csv\" - Average income in each D.R. municipality and occupation for 2013\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.name == 'nt':\n",
    "    base_dir = \"D:/Dropbox/Dropbox (Personal)/College/DR_Paper/\"\n",
    "else:\n",
    "    base_dir = \"/home/j/Dropbox/College/DR_Paper/\"\n",
    "    \n",
    "## INPUTS\n",
    "dhs_geoclust_2007 = base_dir + \"DHS/2007Standard/geo/merge2007clust.csv\"\n",
    "dhs_hhmember_2007 = base_dir + \"DHS/2007Standard/hhmember/DRPR52FL.csv\" # Converted to csv by DHSbuild.R in  main directory\n",
    "dhs_geoclust_2013 = base_dir + \"DHS/2013Standard/geo/merge2013clust.csv\"\n",
    "dhs_hhmember_2013 = base_dir + \"DHS/2013Standard/hhmember/DRPR61FL.csv\" # Converted to csv by DHSbuild.R in  main directory\n",
    "dhs_occupations_conversion = base_dir+\"cafta-dr/DHS/DHSoccupationsISIC.xlsx\"\n",
    "\n",
    "## OUTPUTS\n",
    "averageincmun = base_dir + \"/cafta-dr/Output/averageincomebymunicipality2013.csv\"\n",
    "averageincmunocc = base_dir + \"/cafta-dr/Output/averageincomebyoccmun2013.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the DHS geocluster csvs (merged with ONE municipality codes by 091215extractoneshapefiletopoint.py and converted to csvs by 091215dbftodata.py) and merges them with DHS samples\n",
    "\n",
    "Number of DHS clusters incorrectly marked in another province: 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations with occcupation data 8487\n",
      "Observations classified as having a private employer 3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (503,509,511,547,550,553,555,558,559,634,635,637,708,709,711,787,788,790,811,837,838,839) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#geo_df_2007 = pd.read_csv(dhs_geoclust_2007)\n",
    "#dhs_data_2007 = pd.read_csv(dhs_hhmember_2007)\n",
    "geo_df_2013 = pd.read_csv(dhs_geoclust_2013, encoding='latin_1')\n",
    "dhs_data_2013 = pd.read_csv(dhs_hhmember_2013, encoding='latin_1')\n",
    "\n",
    "## Subset geocluster datasets down to relevant variables\n",
    "geo_keep_cols = ['ADM1DHS','ALT_DEM',\"DHSCLUST\",\"MUN\",\"PROV\",\"REG\",\"URBAN_RURA\"]\n",
    "#geo_df_2007 = geo_df_2007[geo_keep_cols]\n",
    "geo_df_2013 = geo_df_2013[geo_keep_cols]\n",
    "## Merge geodata with DHS data\n",
    "#dhs_data_2007 = dhs_data_2007.merge(geo_df_2007, left_on=\"hv001\", right_on=\"DHSCLUST\", how=\"left\")\n",
    "dhs_data_2013 = dhs_data_2013.merge(geo_df_2013, left_on=\"hv001\", right_on=\"DHSCLUST\", how=\"left\")\n",
    "\n",
    "###May want to apply some correction to municipality displacement. Only problem is correction isn't possible for 2013 data.\n",
    "###Commented section below tests whether different shapefile has better municipality displacement, which it does not.\n",
    "#count = 0 \n",
    "#for i in geo_df_2013.index:\n",
    "#    if geo_df_2013['ADM1DHS'][i] != geo_df_2013['PROV'][i]:\n",
    "#        count += 1\n",
    "#print \"Number of DHS clusters incorrectly marked in another province:\", count\n",
    "\n",
    "### Clean DHS data\n",
    "\n",
    "## Convert occupations provided in espanol to ISIC two digit code\n",
    "## Build conversion dictionary\n",
    "occonversion = pd.read_excel(dhs_occupations_conversion,encoding='latin_1')\n",
    "occonversion['isic2digitV3']=occonversion['isic2digitV3'].astype(str)\n",
    "occonversion['isic2digitV3']=occonversion['isic2digitV3'].apply(lambda x: x.split(','))\n",
    "occonversion = dict(zip(occonversion['espanol'],occonversion['isic2digitV3']))\n",
    "## Take steps necessary to convert occupations\n",
    "dhs_data_2013['sg110'] = dhs_data_2013['sg110'].fillna('missing')\n",
    "dhs_data_2013 = dhs_data_2013[dhs_data_2013['sg110'] != 'missing']\n",
    "dhs_data_2013['sg110'] = dhs_data_2013['sg110'].apply(lambda x: occonversion[x.rstrip()])\n",
    "print \"Observations with occcupation data\", len(dhs_data_2013)\n",
    "\n",
    "## Subset down to workers employed in the private sector \n",
    "## NOT SURE IF I'M  DOING THIS, BUT I DID IT IN IPUMS DATA \n",
    "##Do I want to include the 162 some employers here? 'employer'\n",
    "print \"Observations classified as having a private employer\", len(dhs_data_2013[dhs_data_2013['sg111'] == \"private employee\"])\n",
    "#dhs_data_2013 = dhs_data_2013[dhs_data_2013['sg111'] == \"private employee\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations with income data 7854\n",
      "10451.003947\n",
      "8756.32806935\n",
      "13425.4538088\n",
      "12820.858232\n"
     ]
    }
   ],
   "source": [
    "##Check average income numbers for DR and if they match up with GDP P.C.\n",
    "##2013 -  5,968.7, 2002 - 3,008.5 \n",
    "##Takeaway is that there are several different sources for income data\n",
    "print \"Observations with income data\", len(dhs_data_2013[dhs_data_2013['singresoo'].astype(str) != 'nan'])\n",
    "\n",
    "print dhs_data_2013['singresoo'].mean()\n",
    "print dhs_data_2013['singrthp'].mean()\n",
    "print dhs_data_2013['sg117a'].mean()\n",
    "print dhs_data_2013['singresotp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def codigo(prov):\n",
    "    prov = str(prov)\n",
    "    if len(prov) == 1:\n",
    "        return '0'+prov\n",
    "    else:\n",
    "        return prov\n",
    "\n",
    "#dhs_data_2007 = dhs_data_2007[dhs_data_2007['ingoo'].astype(str) != 'nan']\n",
    "dhs_data_2013 = dhs_data_2013[dhs_data_2013['singresoo'].astype(str) != 'nan']\n",
    "columnstoaggregate = ['singresoo','singrthp','sg117a','singresotp']\n",
    "\n",
    "## Aggregate income at the municipality level\n",
    "muninc2013 = dhs_data_2013.groupby(['PROV','MUN'], as_index=False)[columnstoaggregate].mean()\n",
    "muninc2013['PROV'] = muninc2013['PROV'].astype(str)\n",
    "muninc2013['MUN'] = muninc2013['MUN'].apply(lambda x: codigo(x))\n",
    "muninc2013['CODIGO'] = muninc2013['PROV']+muninc2013['MUN']\n",
    "muninc2013.to_csv(averageincmun, index=False)\n",
    "\n",
    "## Aggregate income at the municipality and occupation level\n",
    "## Duplicate rows into different occupation categories\n",
    "dhs_data_2013 = dhs_data_2013.reset_index()\n",
    "dhs_data_2013.drop('index',1,inplace=True)\n",
    "origrows = list(dhs_data_2013.index)\n",
    "for i in origrows:\n",
    "    numisics = len(dhs_data_2013.loc[i,'sg110'])\n",
    "    if numisics != 1:\n",
    "        updaterows = []\n",
    "        for j in range(numisics)[1:]:\n",
    "            newrow = dict(dhs_data_2013.loc[i,:])\n",
    "            newrow['sg110']=dhs_data_2013.loc[i,'sg110'][j]\n",
    "            updaterows.append(newrow)\n",
    "        dhs_data_2013 = dhs_data_2013.append(updaterows)\n",
    "        dhs_data_2013 = dhs_data_2013.reset_index()\n",
    "        dhs_data_2013.drop('index',1,inplace=True)\n",
    "    \n",
    "    dhs_data_2013.loc[i,'sg110'] = dhs_data_2013.loc[i,'sg110'][0]\n",
    "\n",
    "\n",
    "dhs_data_2013 = dhs_data_2013.groupby(['PROV','MUN','sg110'], as_index=False)[columnstoaggregate].mean()\n",
    "dhs_data_2013['PROV'] = dhs_data_2013['PROV'].astype(str)\n",
    "dhs_data_2013['MUN'] = dhs_data_2013['MUN'].apply(lambda x: codigo(x))\n",
    "dhs_data_2013['CODIGO'] = dhs_data_2013['PROV']+dhs_data_2013['MUN']\n",
    "dhs_data_2013.to_csv(averageincmunocc, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
