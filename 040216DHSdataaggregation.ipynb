{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DHSdataaggregation.py - Takes DHS data and aggregates the variables in the files (most importantly income and wage data) to the occupation and municipality level, after making necessary cleaning and merging steps\n",
    "\n",
    "### Jay Sayre - sayrejay (at) gmai|,\n",
    "\n",
    "## Inputs: \n",
    "\n",
    "\"../DHS/2013Standard/geo/merge2013clust.csv\" - DHS 2013 Dominican Republic geospatial data corresponding to geo-tagged keys in DHS 2013 dataset, compiled by extractoneshapefiletopoint.py\n",
    "\n",
    "\"../DHS/2013Standard/hhmember/DRPR61FL.csv\" - DHS 2013 Dominican Republic Household Member Dataset (converted to csv by DHS/DHSbuild.R script)\n",
    "\n",
    "Ditto for DHS 2007 data (don't think I'm using this)\n",
    "\n",
    "\"/cafta-dr/DHS/DHSoccupationsISIC.xlsx\" - Code for converting DHS occupation categories into ISIC occupation codes, compiled by author (me!)\n",
    "\n",
    "usd2013todr13pesos - Nominal conversion rate from 2013 USD to 2013 RD, times a weighted factor wrt to \n",
    "current 2010 USD (to make this in real terms).\n",
    "\n",
    "## Outputs: \n",
    "\"averageincomebymunicipality2013.csv\" - Average income in each D.R. municipality for 2013\n",
    "\n",
    "\"averageincomebyoccmun2013.csv\" - Average income in each D.R. municipality and occupation for 2013\n",
    "\n",
    "\"averageoccincmun2013highskill.csv\" - Average income in each D.R. municipality and occupation for 2013 for high skill subsample (9 years of education or more)\n",
    "\n",
    "\"averageoccincmun2013lowskill.csv\" - Average income in each D.R. municipality and occupation for 2013 for high skill subsample (less than 9 years of education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.name == 'nt':\n",
    "    base_dir = \"D:/Dropbox/Dropbox (Personal)/College/DR_Paper/\"\n",
    "else:\n",
    "    base_dir = \"/home/j/Dropbox/College/DR_Paper/\"\n",
    "    \n",
    "## INPUTS\n",
    "dhs_geoclust_2007 = base_dir + \"DHS/2007Standard/geo/merge2007clust.csv\"\n",
    "dhs_hhmember_2007 = base_dir + \"DHS/2007Standard/hhmember/DRPR52FL.csv\" # Converted to csv by DHSbuild.R in  main directory\n",
    "dhs_geoclust_2013 = base_dir + \"DHS/2013Standard/geo/merge2013clust.csv\"\n",
    "dhs_hhmember_2013 = base_dir + \"DHS/2013Standard/hhmember/DRPR61FL.csv\" # Converted to csv by DHSbuild.R in  main directory\n",
    "dhs_occupations_conversion = base_dir+\"cafta-dr/DHS/DHSoccupationsISIC.xlsx\"\n",
    "## Conversion rate from 2013 RD to 2013 USD \n",
    "usd2013todr13pesos = 41.8081439153#*(0.985) ## Later term is so currency is wrt to 2010 constant USD, from World Bank\n",
    "\n",
    "## OUTPUTS\n",
    "averageincmun = base_dir + \"cafta-dr/Output/averageincomebymunicipality2013.csv\" ## Comment this out if creating ho/lo skill subsample\n",
    "#averageincmun = base_dir + \"cafta-dr/Output/deleteme.csv\" ## Comment this out if creating full sample\n",
    "averageincmunocc = base_dir + \"cafta-dr/Output/averageincomebyoccmun2013.csv\" ## Comment this out if creating ho/lo skill subsample\n",
    "#averageincmunocc = base_dir+'cafta-dr/Output/averageoccincmun2013highskill.csv' ## Comment this out if creating full sample \n",
    "#averageincmunocc = base_dir+'cafta-dr/Output/averageoccincmun2013lowskill.csv' ## Comment this out if creating full sample \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the DHS geocluster csvs (merged with ONE municipality codes by 091215extractoneshapefiletopoint.py and converted to csvs by 091215dbftodata.py) and merges them with DHS samples\n",
    "\n",
    "Number of DHS clusters incorrectly marked in another province: 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations 41267\n",
      "Observations with occcupation data 8487\n",
      "Observations classified as having a private employer 3281\n",
      "57.6602751338\n",
      "57.5113867132\n",
      "48.1863801915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (503,509,511,547,550,553,555,558,559,634,635,637,708,709,711,787,788,790,811,837,838,839) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "geo_df_2007 = pd.read_csv(dhs_geoclust_2007)\n",
    "dhs_data_2007 = pd.read_csv(dhs_hhmember_2007)\n",
    "geo_df_2013 = pd.read_csv(dhs_geoclust_2013, encoding='latin_1')\n",
    "dhs_data_2013 = pd.read_csv(dhs_hhmember_2013, encoding='latin_1')\n",
    "dhs_data_2013.drop('Unnamed: 0',1,inplace=True)\n",
    "\n",
    "## Subset geocluster datasets down to relevant variables\n",
    "geo_keep_cols = ['ADM1DHS','ALT_DEM',\"DHSCLUST\",\"MUN\",\"PROV\",\"REG\",\"URBAN_RURA\"]\n",
    "geo_df_2007 = geo_df_2007[geo_keep_cols]\n",
    "geo_df_2013 = geo_df_2013[geo_keep_cols]\n",
    "## Merge geodata with DHS data\n",
    "dhs_data_2007 = dhs_data_2007.merge(geo_df_2007, left_on=\"hv001\", right_on=\"DHSCLUST\", how=\"left\")\n",
    "dhs_data_2013 = dhs_data_2013.merge(geo_df_2013, left_on=\"hv001\", right_on=\"DHSCLUST\", how=\"left\")\n",
    "\n",
    "### Clean 2013 DHS data\n",
    "\n",
    "## Convert occupations provided in espanol to ISIC two digit code\n",
    "## Build conversion dictionary\n",
    "occonversion = pd.read_excel(dhs_occupations_conversion,encoding='latin_1')\n",
    "occonversion['isic2digitV3']=occonversion['isic2digitV3'].astype(str)\n",
    "occonversion['isic2digitV3']=occonversion['isic2digitV3'].apply(lambda x: x.split(','))\n",
    "occonversion = dict(zip(occonversion['espanol'],occonversion['isic2digitV3']))\n",
    "occonversion['missing'] = '99'\n",
    "## Take steps necessary to convert occupations in 2013\n",
    "dhs_data_2013['sg110'] = dhs_data_2013['sg110'].fillna('missing')\n",
    "dhs_data_2013['sg110'] = dhs_data_2013['sg110'].apply(lambda x: occonversion[x.rstrip()])\n",
    "print \"Total observations\", len(dhs_data_2013['sg110'])\n",
    "print \"Observations with occcupation data\", len(dhs_data_2013[dhs_data_2013['sg110'] != '99'])\n",
    "\n",
    "## Subset down to workers employed in the private sector \n",
    "## NOT SURE IF I'M  DOING THIS, BUT I DID IT IN IPUMS DATA \n",
    "##Do I want to include the 162 some employers here? 'employer'\n",
    "print \"Observations classified as having a private employer\", len(dhs_data_2013[dhs_data_2013['sg111'] == \"private employee\"])\n",
    "#dhs_data_2013 = dhs_data_2013[dhs_data_2013['sg111'] == \"private employee\"] \n",
    "\n",
    "### Convert income to unified period, convert to 2013 USD\n",
    "## Convert income to correct periodicity, defaults to assuming pay is monthly since it is most common\n",
    "grosssalary_period_conv = {\"monthly\":12,'by weekly':26,'weekly':52,'yearly':1,\"don't know\":12}\n",
    "frstsourcinc_period_conv = {\"monthly\":12,'by weekly':26,'weekly':52,'yearly':1,\"don't know\":12}\n",
    "\n",
    "dhs_data_2013['sg112a'] = dhs_data_2013['sg112a'].apply(lambda x: x if x != 999998 else 0)\n",
    "dhs_data_2013['sg112b'] = dhs_data_2013['sg112b'].apply(lambda x: float(grosssalary_period_conv.get(x,12)))\n",
    "dhs_data_2013['sg117b'] = dhs_data_2013['sg117b'].apply(lambda x: float(frstsourcinc_period_conv.get(x,12)))\n",
    "\n",
    "## Convert income measured in DR 2013 (at different periods) to weekly 2013 USD\n",
    "dhs_data_2013['grossalary'] = (dhs_data_2013['sg112a']*dhs_data_2013['sg112b'])/(usd2013todr13pesos*52.0)\n",
    "dhs_data_2013['frstsourcinc'] = (dhs_data_2013['sg117a']*dhs_data_2013['sg117b'])/(usd2013todr13pesos*52.0)\n",
    "dhs_data_2013['occinc'] = (dhs_data_2013['singresoo']*12)/(usd2013todr13pesos*52.0)\n",
    "\n",
    "##Check average income numbers for DR and if they match up with GDP P.C.\n",
    "##2013 -  5,968.7, 2002 - 3,008.5 \n",
    "#print \"Observations with occ. income data\", len(dhs_data_2013[dhs_data_2013['occinc'].astype(str) != 'nan'])\n",
    "#print \"Observations with salary data\", len(dhs_data_2013[dhs_data_2013['grossalary'].astype(str) != 'nan'])\n",
    "#print \"Observations with first source of inc.\", len(dhs_data_2013[dhs_data_2013['frstsourcinc'].astype(str) != 'nan'])\n",
    "\n",
    "print dhs_data_2013['occinc'].mean()\n",
    "print dhs_data_2013['grossalary'].mean()\n",
    "print dhs_data_2013['frstsourcinc'].mean()\n",
    "\n",
    "## Convert weekly income into estimated hourly wage based upon average working hours for each occupation category\n",
    "## For information on where these numbers come from, please see:\n",
    "## cafta-dr/DR_Codigos/Input/DRCentralBankAverageHoursWorkedbyOccupation.xls\n",
    "def avgworkhrs13(occ):\n",
    "    ## Checks to see if occ is a list\n",
    "    ## Has to be a better way to do this\n",
    "    try:\n",
    "        occ.sort()\n",
    "        occ = int(occ[0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if occ in range(1,3+1):     return 39.62\n",
    "    elif occ in range(5,9+1):   return 44.95\n",
    "    elif occ in range(10,33+1): return 44.23\n",
    "    elif occ in range(35,39+1): return 43.33\n",
    "    elif occ in range(41,43+1): return 41.97\n",
    "    elif occ in range(45,47+1): return 42.57 #Not sure about my translation here\n",
    "    elif occ in range(55,56+1): return 42.03\n",
    "    elif occ in range(49,53+1): return 45.38\n",
    "    elif occ in range(58,63+1): return 45.38\n",
    "    elif occ in range(64,66+1): return 41.30\n",
    "    elif occ in range(77,84+1): return 40.70\n",
    "    elif occ == 84:             return 40.70\n",
    "    elif occ in range(94,96+1): return 38.49\n",
    "    else:                       return 41.28\n",
    "\n",
    "dhs_data_2013['hrsworked'] = dhs_data_2013['sg110'].apply(lambda x: avgworkhrs13(x))\n",
    "dhs_data_2013['grossalary'] = dhs_data_2013['grossalary']/dhs_data_2013['hrsworked']\n",
    "dhs_data_2013['frstsourcinc'] = dhs_data_2013['frstsourcinc']/dhs_data_2013['hrsworked']\n",
    "dhs_data_2013['occinc'] = dhs_data_2013['occinc']/dhs_data_2013['hrsworked']\n",
    "    \n",
    "## Clean up education data\n",
    "dhs_data_2013['yearsedu']=dhs_data_2013['hv108'].apply(lambda x: x if x != 98 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Subset data into high skill (years of education greater or equal to 9) and low skill (educational attainment less than 9)\n",
    "## Before running this process, be sure to change name of output file above to high or low skill respectively\n",
    "\n",
    "#dhs_data_2013 = dhs_data_2013[dhs_data_2013['yearsedu'] >= 9] ## high skill\n",
    "#dhs_data_2013 = dhs_data_2013[dhs_data_2013['yearsedu'] < 9] ## low skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Clean 2007 DHS data\n",
    "\n",
    "## 2007 income data\n",
    "\n",
    "#['gs21a'] salary\n",
    "#['gs21b'] periodicitiy\n",
    "#gs27a - frst source of income\n",
    "#gs27b - periodicity\n",
    "#ingoo - occupational income\n",
    "\n",
    "### Convert occupations - TO DO\n",
    "\n",
    "### Convert income to unified period, convert to 2013 USD\n",
    "## Convert income to correct periodicity, defaults to assuming pay is monthly since it is most common\n",
    "#dhs_data_2007['gs21b'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of N/A occupations: 22\n"
     ]
    }
   ],
   "source": [
    "def codigo(prov):\n",
    "    prov = str(prov)\n",
    "    if len(prov) == 1:\n",
    "        return '0'+prov\n",
    "    else:\n",
    "        return prov\n",
    "\n",
    "## Remove entries with null income data   \n",
    "# dhs_data_2007 = dhs_data_2007[dhs_data_2007['ingoo'].astype(str) != 'nan']\n",
    "dhs_data_2013 = dhs_data_2013[dhs_data_2013['grossalary'].astype(str) != 'nan']\n",
    "columnstoaggregate = ['grossalary','occinc','frstsourcinc','yearsedu']\n",
    "\n",
    "## Remove entries with unknown occupations\n",
    "## Once you subset down to only entries with income data, this only reduces entries by 57 or so \n",
    "print \"Number of N/A occupations:\", len(dhs_data_2013)-len(dhs_data_2013[dhs_data_2013['sg110'] != '99'])\n",
    "dhs_data_2013 =  dhs_data_2013[dhs_data_2013['sg110'] != '99']\n",
    "\n",
    "## Aggregate income, other variables at the municipality level\n",
    "### COULD SUBSET THIS DOWN TO ONLY ENTRIES WITH OCCUPATION DATA, AS BELOW\n",
    "muninc2013 = dhs_data_2013.groupby(['PROV','MUN'], as_index=False)[columnstoaggregate].mean()\n",
    "muninc2013['PROV'] = muninc2013['PROV'].astype(str)\n",
    "muninc2013['MUN'] = muninc2013['MUN'].apply(lambda x: codigo(x))\n",
    "muninc2013['CODIGO'] = muninc2013['PROV']+muninc2013['MUN']\n",
    "muninc2013.to_csv(averageincmun, index=False)\n",
    "\n",
    "## Aggregate income at the municipality and occupation level\n",
    "## Duplicate rows into different occupation categories\n",
    "dhs_data_2013 = dhs_data_2013.reset_index()\n",
    "dhs_data_2013.drop('index',1,inplace=True)\n",
    "origrows = list(dhs_data_2013.index)\n",
    "for i in origrows:\n",
    "    numisics = len(dhs_data_2013.loc[i,'sg110'])\n",
    "    if numisics != 1:\n",
    "        updaterows = []\n",
    "        for j in range(numisics)[1:]:\n",
    "            newrow = dict(dhs_data_2013.loc[i,:])\n",
    "            newrow['sg110']=dhs_data_2013.loc[i,'sg110'][j]\n",
    "            updaterows.append(newrow)\n",
    "        \n",
    "        dhs_data_2013 = dhs_data_2013.append(updaterows)\n",
    "        dhs_data_2013 = dhs_data_2013.reset_index()\n",
    "        dhs_data_2013.drop('index',1,inplace=True)\n",
    "    \n",
    "    dhs_data_2013.loc[i,'sg110'] = dhs_data_2013.loc[i,'sg110'][0]\n",
    "\n",
    "dhs_data_2013 = dhs_data_2013.groupby(['PROV','MUN','sg110'], as_index=False)[columnstoaggregate].mean()\n",
    "dhs_data_2013['PROV'] = dhs_data_2013['PROV'].astype(str)\n",
    "dhs_data_2013['MUN'] = dhs_data_2013['MUN'].apply(lambda x: codigo(x))\n",
    "dhs_data_2013['CODIGO'] = dhs_data_2013['PROV']+dhs_data_2013['MUN']\n",
    "dhs_data_2013.to_csv(averageincmunocc, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
